[[{"l":"DLTA-AI User Guide","p":["DLTA-AI Preview","DLTA-AI is the next generation of annotation tools, integrating the power of Computer Vision SOTA models to Labelme in a seamless expirence and intuitive workflow to make creating image datasets easier than ever before"]},{"i":"why-dlta-ai","l":"Why DLTA-AI?","p":["Open source and customizable annotation tool was created to fill a gap in annotation tools. The customization and giving the user the full control was and will be our priority, from the model selection, input formats and inference parameters, to the export formats and even the User Interface itself. From these options, the goal was to extend the use cases of the concept of annotation tool to other use cases for end users beyond just preparing datasets to train models."]},{"l":"Features","p":["Easy and straightforward Installation process, support for all Operating Systems","User Guide with detailed tutorials for all the features","Full Support of Auto Annotation with different models.","Different annotation options and parameters (e.g., Thresholds)","Export to (literally) any format","Modern and functional User Interface","Dedicated Video Mode","Object Tracking Support","Completely free and open-source, and will always be."]},{"l":"Contributing","p":["DLTA-AI is an open source project and contributions are very welcome","You can contribute in many ways:","Create an issue Reporting bugs \uD83D\uDC1E or suggesting new features \uD83C\uDF1F or just give your feedback \uD83D\uDCDD","Create a pull request to fix bugs or add new features, or just to improve the code quality, optimize performance, documentation, or even just to fix typos","Review pull requests and help with the code review process","Spread the word about DLTA-AI and help us grow the community \uD83C\uDF0E, by sharing the project on social media, or just by telling your friends about it"]},{"l":"Resources","p":["Labelme","Segment Anything (SAM)","MMDetection","ultralytics YOLOv8","mikelbrostrom yolov8_tracking","orjson","icons8"]}],[{"l":"Full Installation"},{"l":"Create a Virtual Environment","p":["It is highly recommended to install DTLA-AI in virtual environment using conda. This will ensure a clean and isolated environment for the installation process. use python=3.8 to avoid any compatibility issues"]},{"l":"Install Pytorch","p":["First, you need to install pytorch according to your device and your OS, if you have GPU, choose CUDA version, otherwise choose CPU version","Example:"]},{"i":"option-1-using-pip","l":"Option 1: Using pip","p":["Installation using pip is more easier since it handles all dependencies","then run it from anywhere using","note that first time running DLTA-AI, it will download a required module, it may take some time","you can also use pip for updating DLTA-AI"]},{"i":"option-2-manual-installation","l":"Option 2: Manual Installation","p":["Download the lastest release from here","install requirements","then Run the tool from DLTA_AI_app directory"]}],[{"i":"executable-cpu-only","l":"Executable (CPU Only)","p":["DLTA-AI is available as an executable, however it's CPU only, so it's not recommended for large datasets. It's currently available for windows and linux only","you can download the lastest release Executable under Assets","The Executable doesn't require any installation, just download and run it from the executable file","Executable image in file explorer"]}],[{"l":"Solutions to possible problems"},{"i":"1-linux-devices","l":"1. (linux devices \uD83D\uDC27)","p":["some linux machines may have this problem","it can be solved simply be installing opencv-headless"]},{"i":"2-windows-devices-","l":"2. (windows devices \uD83E\uDE9F)","p":["some windows machines may have this problem when installing mmdet","You can try","or just use Visual Studio installer to Install MSVC v143 - VS 2022 C++ x64/x86 build tools (Latest)**"]},{"l":"3. Problem in installing mmcv-full","p":["you may often stuck in installing mmcv-full with this message","you can try installing pytorch 1.13.1, instead of the lastest version, you can also refer to this isse"]}],[{"i":"segment-anything-sam","l":"Segment Anything (SAM)","p":["META AI model Segment Anything or SAM is integrated in DLTA-AI in many ways to increase the accuracy of the Annotation process, in a very native user expirience with almost zero effort to install."]},{"l":"Installation","p":["Like all other models, The Model Explorer can be used to install the checkpoints directly with just a single click"]},{"l":"Segmentation","p":["Segment Anything can be used to make Zero-Shot Segmentation of any object. DLTA-AI provides an expiernce similar to the Original Demo with the simple SAM toolbar that supports user-customized shortcuts, and runs locally on the user machine on any image or video."]},{"l":"Enhance Polygons","p":["Beside the usual functionality of Zero-Shot Segmentation, Segment Anything can be used to enhance the accuracy of any polygon, weather it was created by the user or by any other model, by simply selecting the polygon(s) and enhancing them from the toolbar or the context menu."]},{"l":"Interpolation Tracking","p":["DLTA-AI utilizes the power of Segment Anything to provide a very accurate interpolation tracking, that can be used to track any object in a video, and can be used to track multiple objects at the same time."]}],[{"l":"Segmentation","p":["Instance Segmentation is one of the major features in DLTA-AI, from the huge library to the different options and pramaters, to the ability to apply manual edits to the results, DLTA-AI proivdes a fully customizable and easy to use segmentation experience."]},{"l":"Model Selection","p":["The model Selection can be done directly by selecting a segmentation model from the menu, or by selecting a model from the huge library of models in the Model Explorer"]},{"l":"Inferencing","p":["The model can be run on the current image only (works in all input modes) or on all images (directory mode only)"]},{"l":"Visualization Options","p":["you can select the visualization options from the menu, such as showing the segmentation mask, or just bounding box, and the class name and the cofidence scor as well"]},{"l":"Select Classes","p":["you can select some classes among the 80 of COCO classes you can select for just this use (forgotten when you close DLTA-AI) or set them as default classes (saved when you close DLTA-AI)"]},{"l":"Thresholds","p":["To give the annotator the full control and the ability to choose the optimum point in the precision/recall tradeoff, DLTA-AI provides 2 thresholding options"]},{"l":"Confidence Threshold","p":["Confidence threshold is very simple, by just typing the threshold value of setting it through the slider, all predictions with confidence less than the threshold will be ignored"]},{"i":"iou-threshold-for-non-maximum-suppression","l":"IOU Threshold (For Non Maximum Suppression)","p":["DLTA-AI internally applies Non Maximum Suppression (NMS) to the predictions, to remove the overlapping predictions, the IOU threshold is the threshold used in NMS."]}],[{"l":"Input Modes","p":["DLTA-AI provides different options for inputs"]},{"l":"Image Mode","p":["image mode is very simple, just open an imgae and start annotating"]},{"l":"Directory Mode","p":["Directory mode is used to annotate a directory of images, it's very useful when you have a dataset of images and you want to annotate them all at once.","Note that it shows all images within the directory and all subdirectories."]},{"l":"Video Mode","p":["Video mode is used to annotate a video, and provides an integrated video player that allows you to naivgate, play, pause, forward, backward, and jump to a specific frame."]},{"l":"Video as Frames","p":["you can open a video as a directory of frames, this is useful when you want to just annotate some frames of a video. you have the option to set start and end frame, and also the sampling rate i.e., the step between frames."]}],[{"l":"Tracking"},{"l":"Model Selection"},{"l":"Tracking Options"},{"l":"Visualization Options"},{"l":"Edit propagation"},{"l":"Delete Options"}],[{"l":"Interpolation Tracking"},{"l":"Interpolation Method"},{"l":"Linear Interpolation"},{"l":"SAM Interpolation"},{"l":"Interpolation Between"},{"l":"Selected Keyframes"},{"l":"Detected Frames"}],[{"l":"Export","p":["This page is under construction \uD83D\uDEA7, please check back later."]}],[{"l":"Model Explorer","p":["This page is under construction \uD83D\uDEA7, please check back later."]}],[{"l":"Merge Models","p":["This page is under construction \uD83D\uDEA7, please check back later."]}],[{"l":"User Interface","p":["This page is under construction \uD83D\uDEA7, please check back later."]}]]